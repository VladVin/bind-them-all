{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:48:00] Initializing Normalizer\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "import datamol as dm\n",
    "import lohi_splitter as lohi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import polaris as po\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit import RDLogger\n",
    "import seaborn as sns\n",
    "from splito._scaffold_split import get_scaffold\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "sys.path.append('../src')\n",
    "from utils import ECFP_from_smiles, tanimoto_similarity, standardize_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-21 17:48:01.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n",
      "\u001b[32m2024-06-21 17:48:01.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "benchmark = po.load_benchmark(\"polaris/adme-fang-solu-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hi = pd.read_csv('~/data/splits/hi/train.tsv', sep='\\t')\n",
    "train_hi_with_external = pd.read_csv('~/data/splits/hi/train_with_external.tsv', sep='\\t')\n",
    "valid_hi = pd.read_csv('~/data/splits/hi/valid.tsv', sep='\\t')\n",
    "train = pd.read_csv('~/data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('~/data/test.tsv', sep='\\t')\n",
    "train_hi['S'] = 10**train_hi['logS']\n",
    "train_hi_with_external['S'] = 10**train_hi_with_external['logS']\n",
    "valid_hi['S'] = 10**valid_hi['logS']\n",
    "train['S'] = 10**train['logS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2927, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hi_with_external = train_hi_with_external[train_hi_with_external['logS'] >= -1.].reset_index(drop=True)\n",
    "train_hi_with_external.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logS_mean, logS_std = train['logS'].mean(), train['logS'].std()\n",
    "S_mean, S_std = train['S'].mean(), train['S'].std()\n",
    "\n",
    "train_hi['logS_norm'] = (train_hi['logS'] - logS_mean) / logS_std\n",
    "train_hi['S_norm'] = (train_hi['S'] - S_mean) / S_std\n",
    "valid_hi['logS_norm'] = (valid_hi['logS'] - logS_mean) / logS_std\n",
    "valid_hi['S_norm'] = (valid_hi['S'] - S_mean) / S_std\n",
    "train['logS_norm'] = (train['logS'] - logS_mean) / logS_std\n",
    "train['S_norm'] = (train['S'] - S_mean) / S_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = 0.2 * np.random.randn(len(test)) + 1.5\n",
    "sns.histplot(y_pred, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><tr><th>name</th><td>None</td></tr><tr><th>description</th><td></td></tr><tr><th>tags</th><td></td></tr><tr><th>user_attributes</th><td></td></tr><tr><th>owner</th><td>None</td></tr><tr><th>polaris_version</th><td>dev</td></tr><tr><th>benchmark_name</th><td>adme-fang-SOLU-1</td></tr><tr><th>benchmark_owner</th><td><table border=\"1\"><tr><th>slug</th><td>polaris</td></tr><tr><th>external_id</th><td>org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu</td></tr><tr><th>type</th><td>organization</td></tr></table></td></tr><tr><th>github_url</th><td>None</td></tr><tr><th>paper_url</th><td>None</td></tr><tr><th>contributors</th><td>None</td></tr><tr><th>artifact_id</th><td>None</td></tr><tr><th>benchmark_artifact_id</th><td>polaris/adme-fang-solu-1</td></tr><tr><th>results</th><td><table border=\"1\"><thead><tr><th>Test set</th><th>Target label</th><th>Metric</th><th>Score</th></tr></thead><tbody><tr><td>test</td><td>LOG_SOLUBILITY</td><td>mean_absolute_error</td><td>0.5199767201</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>mean_squared_error</td><td>0.6536645301</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>r2</td><td>-0.2056257511</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>spearmanr</td><td>-0.0098429035</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>pearsonr</td><td>-0.0118886754</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>explained_var</td><td>-0.0784179963</td></tr></tbody></table></td></tr></table>"
      ],
      "text/plain": [
       "{\n",
       "  \"name\": null,\n",
       "  \"description\": \"\",\n",
       "  \"tags\": [],\n",
       "  \"user_attributes\": {},\n",
       "  \"owner\": null,\n",
       "  \"polaris_version\": \"dev\",\n",
       "  \"benchmark_name\": \"adme-fang-SOLU-1\",\n",
       "  \"benchmark_owner\": {\n",
       "    \"slug\": \"polaris\",\n",
       "    \"external_id\": \"org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu\",\n",
       "    \"type\": \"organization\"\n",
       "  },\n",
       "  \"github_url\": null,\n",
       "  \"paper_url\": null,\n",
       "  \"contributors\": null,\n",
       "  \"artifact_id\": null,\n",
       "  \"benchmark_artifact_id\": \"polaris/adme-fang-solu-1\",\n",
       "  \"results\": [\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"mean_absolute_error\",\n",
       "      \"Score\": 0.5199767201\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"mean_squared_error\",\n",
       "      \"Score\": 0.6536645301\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"r2\",\n",
       "      \"Score\": -0.2056257511\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"spearmanr\",\n",
       "      \"Score\": -0.0098429035\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"pearsonr\",\n",
       "      \"Score\": -0.0118886754\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"explained_var\",\n",
       "      \"Score\": -0.0784179963\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = benchmark.evaluate(y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renumerate_smiles(smiles):\n",
    "    \"\"\"Perform a randomization of a SMILES string\n",
    "    must be RDKit sanitizable\"\"\"\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    ans = list(range(m.GetNumAtoms()))\n",
    "    np.random.shuffle(ans)\n",
    "    nm = Chem.RenumberAtoms(m,ans)\n",
    "    smiles = Chem.MolToSmiles(nm, canonical=False, isomericSmiles=True)\n",
    "\n",
    "    return smiles\n",
    "\n",
    "def randomly_mask_smiles(mol_sentence: str, mol_masking_val: float, mask_token: int) -> str:\n",
    "    mask = torch.rand((len(mol_sentence),)) >= mol_masking_val\n",
    "    masked_mol_sentence = ''.join([\n",
    "        char if mask[i] else mask_token for i, char in enumerate(mol_sentence)\n",
    "    ])\n",
    "\n",
    "    return masked_mol_sentence\n",
    "\n",
    "class TransformersTokenizer:\n",
    "    def __init__(self, pretrained_model_name_or_path, max_length, padding, truncation, do_lower_case) -> None:\n",
    "        if pretrained_model_name_or_path == 'ibm/MoLFormer-XL-both-10pct':\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                pretrained_model_name_or_path, do_lower_case=do_lower_case, trust_remote_code=True\n",
    "            )\n",
    "        else:\n",
    "            print(f'Loading an unknown tokenizer: {pretrained_model_name_or_path}')\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, use_fast=False, max_len=128)\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.truncation = truncation\n",
    "\n",
    "    def tokenize(self, seq: str) -> tuple[list[int], list[int]]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    def pad_token_id(self) -> int:\n",
    "        return self.tokenizer.pad_token_id\n",
    "\n",
    "\n",
    "class MolTransformersTokenizer(TransformersTokenizer):\n",
    "    def __init__(self, pretrained_model_name_or_path, max_length=128, padding=False, truncation=True) -> None:\n",
    "        super().__init__(\n",
    "            pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
    "            max_length=max_length,\n",
    "            padding=padding,\n",
    "            truncation=truncation,\n",
    "            do_lower_case=False\n",
    "        )\n",
    "\n",
    "    def tokenize(self, smiles: str) -> tuple[list[int], list[int]]:\n",
    "        tokenized = self.tokenizer(smiles, max_length=self.max_length,\n",
    "                                   padding=self.padding, truncation=self.truncation)\n",
    "        \n",
    "        return tokenized['input_ids'], tokenized['attention_mask']\n",
    "\n",
    "\n",
    "class BasicTokenizationDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: TransformersTokenizer, smiles_col: str,\n",
    "                 randomize_smiles: bool = False, mol_masking_prob: float = 0.3, mol_masking_val: float = 0.0,\n",
    "                 truncate: bool = False, eval_mode: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.smiles_col = smiles_col\n",
    "        self.randomize_smiles = randomize_smiles\n",
    "        self.mol_masking_prob = mol_masking_prob\n",
    "        self.mol_masking_val = mol_masking_val\n",
    "        self.tokenizer = tokenizer\n",
    "        self.truncate = truncate\n",
    "        self.eval_mode = eval_mode\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        smiles_orig = self.data.iloc[index][self.smiles_col]\n",
    "\n",
    "        if self.randomize_smiles and (np.random.rand() < 0.5):\n",
    "            smiles = renumerate_smiles(smiles_orig)\n",
    "        else:\n",
    "            smiles = smiles_orig\n",
    "        if (self.mol_masking_val > 0.) and (np.random.rand() < self.mol_masking_prob):\n",
    "            smiles = randomly_mask_smiles(\n",
    "                smiles, self.mol_masking_val, self.tokenizer.tokenizer.mask_token\n",
    "            )\n",
    "\n",
    "        if not self.eval_mode:\n",
    "            label_logs = torch.tensor(self.data.iloc[index]['logS'], dtype=torch.float32)\n",
    "            label_s = torch.tensor(self.data.iloc[index]['S'], dtype=torch.float32)\n",
    "        input_ids, attention_mask = self.tokenizer.tokenize(smiles)\n",
    "\n",
    "        sample = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "        if not self.eval_mode:\n",
    "            sample['label_logs'] = label_logs\n",
    "            sample['label_s'] = label_s\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def collate_fn(self, samples):\n",
    "        input_ids = [sample['input_ids'] for sample in samples]\n",
    "        attention_mask = [sample['attention_mask'] for sample in samples]\n",
    "        input_ids, attention_mask = BasicTokenizationDataset.pad_sequences(\n",
    "            input_ids, attention_mask, self.tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "        batch = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "        if not self.eval_mode:\n",
    "            batch['label_logs'] = torch.stack([sample['label_logs'] for sample in samples])\n",
    "            batch['label_s'] = torch.stack([sample['label_s'] for sample in samples])\n",
    "\n",
    "        return batch\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_sequences(input_ids, attention_mask, pad_token_id=0):\n",
    "        max_seq_len = max([len(inp) for inp in input_ids])\n",
    "        input_ids_ = torch.full((len(input_ids), max_seq_len), pad_token_id, dtype=torch.long)\n",
    "        attention_mask_ = torch.zeros((len(input_ids), max_seq_len), dtype=torch.bool)\n",
    "        for i, (inp, att_mask) in enumerate(zip(input_ids, attention_mask)):\n",
    "            input_ids_[i, :len(inp)] = torch.tensor(inp, dtype=torch.long)\n",
    "            attention_mask_[i, :len(att_mask)] = torch.tensor(att_mask, dtype=torch.long)\n",
    "\n",
    "        return input_ids_, attention_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name_or_path: str, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True, deterministic_eval=True)\n",
    "        self.linear1 = nn.Linear(self.model.config.hidden_size, 512)\n",
    "        self.linear2 = nn.Linear(self.model.config.hidden_size, 512)\n",
    "        # self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier_logs = nn.Linear(512, num_classes)\n",
    "        self.classifier_s = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids, attention_mask)\n",
    "        x = outputs.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(x.size()).type(torch.bool)\n",
    "        x[~input_mask_expanded] = torch.finfo(torch.float16).min  # Set padding tokens to large negative value\n",
    "        feats_max_pool = F.max_pool1d(x.permute(0, 2, 1), kernel_size=x.size(1)).squeeze(-1)\n",
    "        # feats_avg_pool = (x * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(-1).unsqueeze(-1)\n",
    "\n",
    "        # x = torch.cat([self.linear1(feats_max_pool), self.linear2(feats_avg_pool)], dim=1)\n",
    "        x = self.linear1(feats_max_pool)\n",
    "        # x = self.dropout(x)\n",
    "        output_logs = self.classifier_logs(x)\n",
    "        output_s = self.classifier_s(x)\n",
    "\n",
    "        return output_logs, output_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch in tqdm(data_loader):\n",
    "        batch = {k: v.cuda() for k, v in batch.items()}\n",
    "        input_ids, attention_mask = batch['input_ids'], batch['attention_mask']\n",
    "        label_logs, label_s = batch['label_logs'], batch['label_s']\n",
    "        output_logs, output_s = model(input_ids, attention_mask)\n",
    "        output_logs, output_s = output_logs.squeeze(-1), output_s.squeeze(-1)\n",
    "        loss_logs = criterion(output_logs, label_logs)\n",
    "        loss = loss_logs\n",
    "        # loss_s = criterion(output_s, label_s)\n",
    "        # loss = loss_logs + loss_s\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def eval_step(model, data_loader, test_mode=False):\n",
    "    model.eval()\n",
    "    predictions_logs, predictions_s = [], []\n",
    "    for batch in data_loader:\n",
    "        batch = {k: v.cuda() for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            output_logs, output_s = model(batch['input_ids'], batch['attention_mask'])\n",
    "            output_logs, output_s = output_logs.squeeze(-1), output_s.squeeze(-1)\n",
    "        predictions_logs.append(output_logs.detach().cpu().numpy())\n",
    "    predictions_logs = np.concatenate(predictions_logs)\n",
    "    # predictions_logs = predictions_logs * logS_std + logS_mean\n",
    "\n",
    "    if test_mode:\n",
    "        return None, predictions_logs\n",
    "    else:\n",
    "        r2 = r2_score(data_loader.dataset.data['logS'], predictions_logs)\n",
    "        return r2, predictions_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Hi Loss: 1.0718 Valid Hi R2: 9.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Hi Loss: 1.0718 Train submit Loss: 0.7717 Valid Hi R2: 9.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Hi Loss: 0.5328 Valid Hi R2: 7.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Hi Loss: 0.5328 Train submit Loss: 0.4702 Valid Hi R2: 7.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Hi Loss: 0.3831 Valid Hi R2: 9.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Hi Loss: 0.3831 Train submit Loss: 0.3475 Valid Hi R2: 9.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Hi Loss: 0.3544 Valid Hi R2: 14.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Hi Loss: 0.3544 Train submit Loss: 0.2928 Valid Hi R2: 14.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Hi Loss: 0.3294 Valid Hi R2: 22.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Hi Loss: 0.3294 Train submit Loss: 0.2732 Valid Hi R2: 22.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Hi Loss: 0.2919 Valid Hi R2: 22.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Hi Loss: 0.2919 Train submit Loss: 0.2688 Valid Hi R2: 22.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Hi Loss: 0.2664 Valid Hi R2: 31.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Hi Loss: 0.2664 Train submit Loss: 0.2487 Valid Hi R2: 31.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Hi Loss: 0.2479 Valid Hi R2: 31.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Hi Loss: 0.2479 Train submit Loss: 0.2290 Valid Hi R2: 31.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train Hi Loss: 0.2326 Valid Hi R2: 30.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train Hi Loss: 0.2326 Train submit Loss: 0.2198 Valid Hi R2: 30.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Hi Loss: 0.2286 Valid Hi R2: 26.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Hi Loss: 0.2286 Train submit Loss: 0.2149 Valid Hi R2: 26.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Hi Loss: 0.2142 Valid Hi R2: 28.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Hi Loss: 0.2142 Train submit Loss: 0.2160 Valid Hi R2: 28.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Hi Loss: 0.1933 Valid Hi R2: 29.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Hi Loss: 0.1933 Train submit Loss: 0.1910 Valid Hi R2: 29.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Hi Loss: 0.1800 Valid Hi R2: 27.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Hi Loss: 0.1800 Train submit Loss: 0.2019 Valid Hi R2: 27.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Hi Loss: 0.1640 Valid Hi R2: 29.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Hi Loss: 0.1640 Train submit Loss: 0.1874 Valid Hi R2: 29.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Hi Loss: 0.1527 Valid Hi R2: 31.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Hi Loss: 0.1527 Train submit Loss: 0.1564 Valid Hi R2: 31.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Hi Loss: 0.1489 Valid Hi R2: 25.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Hi Loss: 0.1489 Train submit Loss: 0.1525 Valid Hi R2: 25.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Hi Loss: 0.1417 Valid Hi R2: 25.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Hi Loss: 0.1417 Train submit Loss: 0.1546 Valid Hi R2: 25.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train Hi Loss: 0.1496 Valid Hi R2: 22.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train Hi Loss: 0.1496 Train submit Loss: 0.1628 Valid Hi R2: 22.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:03,  2.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m---> 33\u001b[0m     train_hi_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_hi_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriteria_mse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     valid_hi_r2, _ \u001b[38;5;241m=\u001b[39m eval_step(model, valid_hi_dataloader)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Hi Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_hi_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Valid Hi R2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_hi_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, data_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# loss_s = criterion(output_s, label_s)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# loss = loss_logs + loss_s\u001b[39;00m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/chem/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chem/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chem/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4\n",
    "\n",
    "model = Model('ibm/MoLFormer-XL-both-10pct', 1)\n",
    "model = model.cuda()\n",
    "model_submit = Model('ibm/MoLFormer-XL-both-10pct', 1)\n",
    "model_submit = model_submit.cuda()\n",
    "best_model, best_model_submit = None, None\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "optimizer_submit = torch.optim.Adam(model_submit.parameters(), lr=LR)\n",
    "criteria_mse = nn.MSELoss()\n",
    "\n",
    "tokenizer = MolTransformersTokenizer(\"ibm/MoLFormer-XL-both-10pct\", max_length=128)\n",
    "train_hi_dataset = BasicTokenizationDataset(\n",
    "    train_hi, tokenizer, randomize_smiles=True, smiles_col='smiles', eval_mode=False, mol_masking_val=0.15\n",
    ")\n",
    "valid_hi_dataset = BasicTokenizationDataset(valid_hi, tokenizer, smiles_col='smiles')\n",
    "train_dataset = BasicTokenizationDataset(\n",
    "    train, tokenizer, randomize_smiles=True, smiles_col='smiles', eval_mode=False, mol_masking_val=0.15\n",
    ")\n",
    "test_dataset = BasicTokenizationDataset(test, tokenizer, smiles_col='smiles')\n",
    "\n",
    "train_hi_dataloader = DataLoader(train_hi_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_hi_dataset.collate_fn)\n",
    "valid_hi_dataloader = DataLoader(valid_hi_dataset, batch_size=512, shuffle=False, collate_fn=valid_hi_dataset.collate_fn)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=False, collate_fn=test_dataset.collate_fn)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "torch.set_grad_enabled(True)\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_hi_loss = train_step(model, train_hi_dataloader, optimizer, criteria_mse)\n",
    "    valid_hi_r2, _ = eval_step(model, valid_hi_dataloader)\n",
    "    print(f'Epoch: {epoch}, Train Hi Loss: {train_hi_loss:.4f} Valid Hi R2: {valid_hi_r2:.2%}')\n",
    "\n",
    "    train_submit_loss = train_step(model_submit, train_dataloader, optimizer_submit, criteria_mse)\n",
    "    print(f'Epoch: {epoch}, Train Hi Loss: {train_hi_loss:.4f} Train submit Loss: {train_submit_loss:.4f} Valid Hi R2: {valid_hi_r2:.2%}')\n",
    "\n",
    "    if valid_hi_r2 > best_r2:\n",
    "        best_r2 = valid_hi_r2\n",
    "        best_model_submit = copy.deepcopy(model_submit)\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "print(f'Best VALID R2: {best_r2:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><tr><th>name</th><td>None</td></tr><tr><th>description</th><td></td></tr><tr><th>tags</th><td></td></tr><tr><th>user_attributes</th><td></td></tr><tr><th>owner</th><td>None</td></tr><tr><th>polaris_version</th><td>dev</td></tr><tr><th>benchmark_name</th><td>adme-fang-SOLU-1</td></tr><tr><th>benchmark_owner</th><td><table border=\"1\"><tr><th>slug</th><td>polaris</td></tr><tr><th>external_id</th><td>org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu</td></tr><tr><th>type</th><td>organization</td></tr></table></td></tr><tr><th>github_url</th><td>None</td></tr><tr><th>paper_url</th><td>None</td></tr><tr><th>contributors</th><td>None</td></tr><tr><th>artifact_id</th><td>None</td></tr><tr><th>benchmark_artifact_id</th><td>polaris/adme-fang-solu-1</td></tr><tr><th>results</th><td><table border=\"1\"><thead><tr><th>Test set</th><th>Target label</th><th>Metric</th><th>Score</th></tr></thead><tbody><tr><td>test</td><td>LOG_SOLUBILITY</td><td>mean_absolute_error</td><td>0.3955394886</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>mean_squared_error</td><td>0.359670682</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>r2</td><td>0.3366196021</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>spearmanr</td><td>0.5382854166</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>pearsonr</td><td>0.6009388904</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>explained_var</td><td>0.3417272786</td></tr></tbody></table></td></tr></table>"
      ],
      "text/plain": [
       "{\n",
       "  \"name\": null,\n",
       "  \"description\": \"\",\n",
       "  \"tags\": [],\n",
       "  \"user_attributes\": {},\n",
       "  \"owner\": null,\n",
       "  \"polaris_version\": \"dev\",\n",
       "  \"benchmark_name\": \"adme-fang-SOLU-1\",\n",
       "  \"benchmark_owner\": {\n",
       "    \"slug\": \"polaris\",\n",
       "    \"external_id\": \"org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu\",\n",
       "    \"type\": \"organization\"\n",
       "  },\n",
       "  \"github_url\": null,\n",
       "  \"paper_url\": null,\n",
       "  \"contributors\": null,\n",
       "  \"artifact_id\": null,\n",
       "  \"benchmark_artifact_id\": \"polaris/adme-fang-solu-1\",\n",
       "  \"results\": [\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"mean_absolute_error\",\n",
       "      \"Score\": 0.3955394886\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"mean_squared_error\",\n",
       "      \"Score\": 0.359670682\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"r2\",\n",
       "      \"Score\": 0.3366196021\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"spearmanr\",\n",
       "      \"Score\": 0.5382854166\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"pearsonr\",\n",
       "      \"Score\": 0.6009388904\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"explained_var\",\n",
       "      \"Score\": 0.3417272786\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, test_predictions_logs = eval_step(best_model_submit, test_dataloader, test_mode=True)\n",
    "results = benchmark.evaluate(test_predictions_logs)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_molformer_preds = test_predictions_logs\n",
    "test_xgb_preds = np.load('/home/ubuntu/data/Results/XGB_results.npy')\n",
    "test_preds = 0.5 * test_molformer_preds + 0.5 * test_xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><tr><th>name</th><td>ML4DD-team10</td></tr><tr><th>description</th><td>https://docs.google.com/document/d/1sjtQgNrN6tdnXqJiUjNT_nHbRnFH632FqWikktldiM4/edit?usp=sharing</td></tr><tr><th>tags</th><td></td></tr><tr><th>user_attributes</th><td></td></tr><tr><th>owner</th><td>None</td></tr><tr><th>polaris_version</th><td>dev</td></tr><tr><th>benchmark_name</th><td>adme-fang-SOLU-1</td></tr><tr><th>benchmark_owner</th><td><table border=\"1\"><tr><th>slug</th><td>polaris</td></tr><tr><th>external_id</th><td>org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu</td></tr><tr><th>type</th><td>organization</td></tr></table></td></tr><tr><th>github_url</th><td>https://github.com/VladVin/bind-them-all</td></tr><tr><th>paper_url</th><td>None</td></tr><tr><th>contributors</th><td>None</td></tr><tr><th>artifact_id</th><td>None</td></tr><tr><th>benchmark_artifact_id</th><td>polaris/adme-fang-solu-1</td></tr><tr><th>results</th><td><table border=\"1\"><thead><tr><th>Test set</th><th>Target label</th><th>Metric</th><th>Score</th></tr></thead><tbody><tr><td>test</td><td>LOG_SOLUBILITY</td><td>mean_absolute_error</td><td>0.4103523524</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>mean_squared_error</td><td>0.3444609919</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>r2</td><td>0.3646725148</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>spearmanr</td><td>0.5689948257</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>pearsonr</td><td>0.6253709212</td></tr><tr><td>test</td><td>LOG_SOLUBILITY</td><td>explained_var</td><td>0.3694326684</td></tr></tbody></table></td></tr></table>"
      ],
      "text/plain": [
       "{\n",
       "  \"name\": \"ML4DD-team10\",\n",
       "  \"description\": \"https://docs.google.com/document/d/1sjtQgNrN6tdnXqJiUjNT_nHbRnFH632FqWikktldiM4/edit?usp=sharing\",\n",
       "  \"tags\": [],\n",
       "  \"user_attributes\": {},\n",
       "  \"owner\": null,\n",
       "  \"polaris_version\": \"dev\",\n",
       "  \"benchmark_name\": \"adme-fang-SOLU-1\",\n",
       "  \"benchmark_owner\": {\n",
       "    \"slug\": \"polaris\",\n",
       "    \"external_id\": \"org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu\",\n",
       "    \"type\": \"organization\"\n",
       "  },\n",
       "  \"github_url\": \"https://github.com/VladVin/bind-them-all\",\n",
       "  \"paper_url\": null,\n",
       "  \"contributors\": null,\n",
       "  \"artifact_id\": null,\n",
       "  \"benchmark_artifact_id\": \"polaris/adme-fang-solu-1\",\n",
       "  \"results\": [\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"mean_absolute_error\",\n",
       "      \"Score\": 0.4103523524\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"mean_squared_error\",\n",
       "      \"Score\": 0.3444609919\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"r2\",\n",
       "      \"Score\": 0.3646725148\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"spearmanr\",\n",
       "      \"Score\": 0.5689948257\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"pearsonr\",\n",
       "      \"Score\": 0.6253709212\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"LOG_SOLUBILITY\",\n",
       "      \"Metric\": \"explained_var\",\n",
       "      \"Score\": 0.3694326684\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = benchmark.evaluate(test_preds)\n",
    "results.name = 'ML4DD-team10'\n",
    "results.description = 'https://docs.google.com/document/d/1sjtQgNrN6tdnXqJiUjNT_nHbRnFH632FqWikktldiM4/edit?usp=sharing'\n",
    "results.github_url = 'https://github.com/VladVin/bind-them-all'\n",
    "# results.contributors = ['vladvin', 'zhwm', 'BenjaminWeiser' 'anoushka2000']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-21 17:57:48.909\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mpolaris.hub.client\u001b[0m:\u001b[36mupload_results\u001b[0m:\u001b[36m492\u001b[0m - \u001b[32m\u001b[1mYour result has been successfully uploaded to the Hub. View it here: https://polarishub.io/benchmarks/polaris/adme-fang-SOLU-1/jW64wueaTFK6YhvwHoRdA\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results.upload_to_hub(owner='vladvin');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
